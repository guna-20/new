{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ7VThOnp9WX"
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I9JjyFSs4LZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS2oJaDAtpAz",
        "outputId": "4eb114cf-3ce0-4bfb-8281-b4569cdc7dc9"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "3_C3RjKjtxh8",
        "outputId": "ca22ae2e-246b-4cdd-ac91-c5bdbbf8a0d0"
      },
      "source": [
        "cols=['sentiment','id','date','query','user','text']\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Projects/Twitter_sentiment_analysis/training.1600000.processed.noemoticon.csv\",\n",
        "               engine='python',\n",
        "               header=None,\n",
        "               names=cols,\n",
        "               encoding=\"Latin1\")\n",
        "#   Latin1 encoding because it accept any possible byte as input, convert into unicode character\n",
        "\n",
        "df.drop(['id','date','query','user'],axis=1,inplace=True)\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>Just woke up. Having no school is the best fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment                                               text\n",
              "1599995          4  Just woke up. Having no school is the best fee...\n",
              "1599996          4  TheWDB.com - Very cool to hear old Walt interv...\n",
              "1599997          4  Are you ready for your MoJo Makeover? Ask me f...\n",
              "1599998          4  Happy 38th Birthday to my boo of alll time!!! ...\n",
              "1599999          4  happy #charitytuesday @theNSPCC @SparksCharity..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miTnPgROuPTW"
      },
      "source": [
        "def clean_data(tweet):\n",
        "  tweet = BeautifulSoup(tweet,\"lxml\").get_text()\n",
        "  #  \"<html><head><title>test<body><h1>page title</h3>\" ----> test page title\n",
        "  \n",
        "  tweet = re.sub(r\"@[a-zA-Z0-9]+\",'',tweet)\n",
        "  #  \"@hello i am good\" -----> \"i am good\"\n",
        "  \n",
        "  tweet = re.sub(r\"https?://[a-zA-Z0-9./]+\",'',tweet)\n",
        "  #  \"https://zindi.africa/competitions\" -----> \"\"\n",
        "  \n",
        "  tweet = re.sub(r\"[^a-zA-Z.!?']+\",\" \",tweet)\n",
        "  #   \"*hello i am good 900\" -----> hollo i am good\n",
        "  \n",
        "  tweet = re.sub(r\" +\",\" \",tweet)\n",
        "  #   double spaces are removed\n",
        "  return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2o-HoYcVVBy"
      },
      "source": [
        "cleaned_data=[clean_data(tweet) for tweet in df.text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAVfuBo22Q4G"
      },
      "source": [
        "df_labels=df.sentiment.values\n",
        "df_labels[df_labels==4]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeK-Ipiww7gN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OyUzh5VDo2H",
        "outputId": "e8fb57e6-ccc1-4b7d-94a0-476afb328ad2"
      },
      "source": [
        "cleaned_data[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\",\n",
              " \"is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9kUBTtpp0FN"
      },
      "source": [
        "\n",
        "vocab_size = 2000000\n",
        "embedding_dim = 16\n",
        "max_length = 200\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fZAI_XobNiu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(cleaned_data, df_labels, test_size=0.30, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMTGSw9EJUu2"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "# num_words is no. of words it should take into account. and num_words should ve as much as possible (without stop words)\n",
        "\n",
        "tokenizer.fit_on_texts(cleaned_data)\n",
        "word_index = tokenizer.word_index\n",
        "#  \"The cat sat on the mat.\"  -----> {'cat': 2, 'mat': 5, 'on': 4, 'sat': 3, 'the': 1}\n",
        "# lesser the word_index value, it has occured frequently in the context\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "# values are assigned in place of words based on the word index\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "# trunc removing extra words\n",
        "# adding \"0\"s to sequence\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paRngJQckSop"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D51_vDq0kZ-7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFFaGCdX5_ZM"
      },
      "source": [
        "#We store this tokenizer in a file to use later in web app\n",
        "import pickle\n",
        "# saving\n",
        "with open('/content/drive/MyDrive/Projects/Twitter sentiment analysis/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLxlrDyhTPB-"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPool1D, Dense, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5j7TyFBbRK1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G95NswFGU86S"
      },
      "source": [
        "VOCAB_SIZE =vocab_size\n",
        "EMB_DIM = 200\n",
        "nb_filters  = 50  \n",
        "FFN_units = 200\n",
        "NB_CLASSES = 2\n",
        "dropout_rate = 0.2\n",
        "BATCH_SIZE = 32\n",
        "NB_EPOCHS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlflSIbCTraw"
      },
      "source": [
        "model1 = Sequential()\n",
        "#  it does not allow you to create models that share layers or have multiple inputs or outputs\n",
        "\n",
        "model1.add(tf.keras.layers.Embedding( vocab_size, embedding_dim, input_length=max_length))\n",
        "# Word embeddings provide a dense representation of words and their relative meanings.\n",
        "# input_dim: This is the size of the vocabulary in the text data.\n",
        "# embeding_dim : a vector space of 16 dimensions\n",
        "# input_length : length of each input document \n",
        "\n",
        "model1.add(Conv1D(filters=nb_filters,\n",
        "                                kernel_size=2,\n",
        "                                padding = 'valid',\n",
        "                                activation = \"relu\"))\n",
        "# \"valid\" applies padding to the input sequence so the output size shrinks by filter_size - 1. No padding occurs.\n",
        "# relu because return positive values and negative values as zero.\n",
        "model1.add(Conv1D(filters = nb_filters,\n",
        "                                 kernel_size = 3,\n",
        "                                 padding = \"valid\",\n",
        "                                 activation = \"relu\"))\n",
        "model1.add(Conv1D(filters = nb_filters,\n",
        "                                 kernel_size = 4,\n",
        "                                 padding = \"valid\",\n",
        "                                activation = 'relu'))\n",
        "model1.add(GlobalMaxPool1D())\n",
        "# Downsamples the input representation by taking the maximum value over the time dimension.\n",
        "# shape = input_length,input_channel\n",
        "\n",
        "model1.add(Dense(units = FFN_units,activation = \"relu\"))\n",
        "model1.add(Dropout(rate = dropout_rate))\n",
        "# dropout layer is to prevent overfitting.\n",
        "\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "# \"sigmoid\" because we want output ranging between 0 and 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1t1RjwUnC3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61558793-cbb5-4098-ab1b-de5309b4d1f1"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 16)           32000000  \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 199, 50)           1650      \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 197, 50)           7550      \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 194, 50)           10050     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               10200     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 32,029,651\n",
            "Trainable params: 32,029,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBg8OMTfKW_t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytx6mFBfQM94"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM9VAkWgRnQT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2Gv5y7kVcWK"
      },
      "source": [
        "model1.compile(loss = \"binary_crossentropy\",\n",
        "               optimizer = 'adam',\n",
        "               metrics = ['accuracy'])\n",
        "\n",
        "# binary_crossentropy because its a binary__classificartion problem (  -(1/N) sum(y * log(yhat) + (1 -y) * log(1 - yhat)) )\n",
        "# optimizer deals with learning rate and when should update weight."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KelrfM0TNjE"
      },
      "source": [
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/Projects/Twitter sentiment analysis/checkpoint/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(model1)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "zY6cY3-9UQ6d",
        "outputId": "cdd420db-2b16-4840-e86c-28bc4e595d31"
      },
      "source": [
        "model1.fit(training_padded,y_train,validation_data= (testing_padded,y_test),batch_size = 2**8, epochs = NB_EPOCHS, verbose =1) \n",
        "ckpt_manager.save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4375/4375 [==============================] - 726s 166ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.3939 - val_accuracy: 0.8214\n",
            "Epoch 2/2\n",
            "4375/4375 [==============================] - 725s 166ms/step - loss: 0.3610 - accuracy: 0.8406 - val_loss: 0.3956 - val_accuracy: 0.8227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Projects/Twitter sentiment analysis/checkpoint/ckpt-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXahPtlnUs-y",
        "outputId": "f77fd901-e937-4f0e-951e-1f6ca6684ded"
      },
      "source": [
        "predict_1 = model1.predict(testing_padded,batch_size = 2**8,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 4s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49g-zfUmU-YY"
      },
      "source": [
        "ori = lambda x:0 if x<0.5 else 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tuCNcrXVA4n"
      },
      "source": [
        "predict_1_y = list(map(ori,predict_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3gY77zR_wMb",
        "outputId": "561ac04b-1c47-46a5-9a2a-b2cd378b0b41"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predict_1_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82    239361\n",
            "           1       0.83      0.81      0.82    240639\n",
            "\n",
            "    accuracy                           0.82    480000\n",
            "   macro avg       0.82      0.82      0.82    480000\n",
            "weighted avg       0.82      0.82      0.82    480000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-MbEe6FAMxs"
      },
      "source": [
        "sen = [\"i love him\"]\n",
        "tokenizer=tfds.deprecated.text.Tokenizer()\n",
        "input_data1 = [tokenizer.tokenize(i) for i in sen]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Nf9l4aCJ0B"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "sen = tokenizer.texts_to_sequences(input_data1)\n",
        "#sen= pad_sequences(sen, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n-bD8ifgkwu",
        "outputId": "33b8ab00-da10-4c12-9271-b655aec343e9"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1120000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMEiogYki99N",
        "outputId": "fc55157b-a44c-4134-c36a-42410a6814c4"
      },
      "source": [
        "reviews = ['they made me cry', 'I hate spaghetti',\n",
        "           \"he couldn't make it\", \n",
        "                'Everything was good',\n",
        "                'he is a theif', \n",
        "                'Everything was green', \n",
        "                'the host seated us immediately',\n",
        "                'they gave us free chocolate cake', \n",
        "                'not sure about the wilted flowers on the table',\n",
        "                'only works when I stand on tippy toes', \n",
        "              \"everyone was happy \"]\n",
        "\n",
        "ori = lambda x:0 if x<0.5 else 1\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "sample_data=[clean_data(tweet) for tweet in reviews]\n",
        "#sample_stop = [stop_remove(i) for i in sample_data]\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_data)\n",
        "reviews_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)           \n",
        "classes = model1.predict(reviews_padded)\n",
        "classes_y=list( map(ori,classes))\n",
        "for i in range(len(reviews)):\n",
        "  print(reviews[i],classes_y[i])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "they made me cry 0\n",
            "I hate spaghetti 0\n",
            "he couldn't make it 0\n",
            "Everything was good 1\n",
            "he is a theif 1\n",
            "Everything was green 1\n",
            "the host seated us immediately 1\n",
            "they gave us free chocolate cake 1\n",
            "not sure about the wilted flowers on the table 1\n",
            "only works when I stand on tippy toes 0\n",
            "everyone was happy  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYJmjWvj6Uw-"
      },
      "source": [
        "model1.save(\"/content/drive/MyDrive/Projects/Twitter sentiment analysis/sentient_model1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poM3Y36G-1MU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HJhxTbZ-1Jb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU_cg8Fx-3Zh"
      },
      "source": [
        "**For web app**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSuii0MVH1aO"
      },
      "source": [
        "#!pip install streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ_kzc-k-1HI"
      },
      "source": [
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from bs4 import BeautifulSoup\n",
        "#import streamlit as st"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr4PoPko-1E9"
      },
      "source": [
        "def clean_data(tweet):\n",
        "  tweet = BeautifulSoup(tweet,\"lxml\").get_text()\n",
        "  tweet = re.sub(r\"@[a-zA-Z0-9]+\",'',tweet)\n",
        "  tweet = re.sub(r\"https?://[a-zA-Z0-9./]+\",'',tweet)\n",
        "  tweet = re.sub(r\"[^a-zA-Z.!?']+\",\" \",tweet)\n",
        "  tweet = re.sub(r\" +\",\" \",tweet)\n",
        "\n",
        "  return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-h6PGTo-1CZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6bSuhkgqWX1"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/Projects/Twitter_sentiment_analysis/tokenizer.pickle\", \"rb\") as handle:\n",
        " tokenizer = pickle.load(handle)\n",
        "model=load_model('/content/drive/MyDrive/Projects/Twitter_sentiment_analysis/sentient_model1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8NTHdJb_V6V",
        "outputId": "84eb97e5-a6c6-491b-9aa4-c1ac3c63a3d5"
      },
      "source": [
        "reviews = ['they made me cry', 'I hate spaghetti',\n",
        "           \"he couldn't make it\", \n",
        "                'Everything was good',\n",
        "                'he is a theif', \n",
        "                'Everything was green', \n",
        "                'the host seated us immediately',\n",
        "                'they gave us free chocolate cake', \n",
        "                'not sure about the wilted flowers on the table',\n",
        "                'only works when I stand on tippy toes', \n",
        "              \"everyone was happy \"]\n",
        "\n",
        "ori = lambda x:1 if x >0.6 else 0\n",
        "# Create the sequences\n",
        "padding_type='post'\n",
        "sample_data=[clean_data(tweet) for tweet in reviews]\n",
        "#sample_stop = [stop_remove(i) for i in sample_data]\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_data)\n",
        "reviews_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=200)           \n",
        "classes = model.predict(reviews_padded)\n",
        "classes_y=list(map(ori,classes))\n",
        "for i in range(len(reviews)):\n",
        "  print(reviews[i],classes_y[i])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 52) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 200).\n",
            "they made me cry 0\n",
            "I hate spaghetti 0\n",
            "he couldn't make it 0\n",
            "Everything was good 1\n",
            "he is a theif 1\n",
            "Everything was green 1\n",
            "the host seated us immediately 1\n",
            "they gave us free chocolate cake 1\n",
            "not sure about the wilted flowers on the table 1\n",
            "only works when I stand on tippy toes 0\n",
            "everyone was happy  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnMRD5r9AWt-"
      },
      "source": [
        "def predict(message):\n",
        " model=load_model('/content/drive/MyDrive/Projects/Twitter_sentiment_analysis/sentient_model1.h5')\n",
        " with open(\"/content/drive/MyDrive/Projects/Twitter_sentiment_analysis/tokenizer.pickle\", \"rb\") as handle:\n",
        "  tokenizer = pickle.load(handle)\n",
        " x_1 = tokenizer.texts_to_sequences([message])\n",
        " x_1 = pad_sequences(x_1, maxlen=500)\n",
        " predictions = model.predict(x_1)[0][0]\n",
        " ori = 1 if predictions >0.6 else 0\n",
        " return (predictions,ori)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORV28vUwAozC",
        "outputId": "98df475a-58fc-424b-f81c-3c85d6020660"
      },
      "source": [
        "predict(\"i have to much of workload \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 52) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 500).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.22874281, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    }
  ]
}